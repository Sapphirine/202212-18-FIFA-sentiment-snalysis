{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# !pip install tensorflow==2.7.0"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# !pip list"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import datetime as dt\n","import re\n","import subprocess\n","# import tensorflow as tf\n","import time\n","\n","from google.cloud import bigquery\n","from pyspark import SparkConf, SparkContext, SparkFiles\n","from pyspark.sql import SQLContext\n","from pyspark.streaming import StreamingContext"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# global variables\n","bucket = \"6893_project_data\"\n","saved_models_dir = \"gs://{}/saved_models/\".format(bucket)\n","output_data_dir = \"gs://{}/output/twitter_stream\".format(bucket)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# parameter\n","IP = \"localhost\"  # ip port\n","PORT = 9001  # port\n","\n","STREAM_TIME = 60  # time that the streaming process runs\n","INTERVAL = 5"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Helper functions\n","def save_to_storage(rdd, output_directory, column_name, mode):\n","    \"\"\"\n","    Save each RDD in this DStream to google storage\n","    Args:\n","        rdd: input rdd\n","        output_directory: output directory in google storage\n","        column_name: columns name of dataframe\n","        mode: mode = \"overwrite\", overwrite the file\n","              mode = \"append\", append data to the end of file\n","    \"\"\"\n","    if not rdd.isEmpty():\n","        data = rdd.toDF()\n","        print(data)\n","        data.write.save(output_directory, format = \"json\", mode = mode)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def clean_text(text):\n","    text = re.sub(r\"https?:\\/\\/\\S*\\s?\", \"\", text)\n","    text = re.sub(r\"@\\w+\", \"\", text)\n","    text = re.sub(r\"#\\w+\", \"\", text)\n","    text = re.sub(r\"\\n\", \" \", text)\n","    return text"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["<pyspark.conf.SparkConf at 0x7f5f3f6696d0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Spark settings\n","conf = SparkConf()\n","conf.setMaster(\"local[2]\")\n","conf.setAppName(\"TwitterStreamApp\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Create spark context with the above configuration\n","sc = SparkContext(conf = conf)\n","sc.setLogLevel(\"ERROR\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Create sql context, used for saving rdd\n","sql_context = SQLContext(sc)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# create the Streaming Context from the above spark context with batch interval size 5 seconds\n","ssc = StreamingContext(sc, INTERVAL)\n","# setting a checkpoint to allow RDD recovery\n","ssc.checkpoint(\"~/checkpoint_TwitterApp\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# read data from port 9001\n","data_stream = ssc.socketTextStream(IP, PORT)\n","data_stream.pprint()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["data_stream = data_stream.map(lambda t: clean_text(t))\n","data_stream.pprint()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["data_stream.foreachRDD(lambda rdd: save_to_storage(rdd, output_data_dir, [\"text\"], mode = \"overwrite\"))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# !pip install tensorflow-text"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# import tensorflow_text as text"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# model = tf.keras.models.load_model(saved_models_dir + \"twitter_bert\", compile = False)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# def predict_text(data):\n","#     sent_pred = data.map(lambda t: model.predict([t]))\n","#     return sent_pred"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# text_sent = predict_text(data_stream)\n","# text_sent.pprint()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------\n","Time: 2022-12-21 02:12:00\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:00\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:05\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:05\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:10\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:10\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:15\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:15\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:20\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:20\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:25\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:25\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:30\n","-------------------------------------------\n","@CMonteroOficial En caso de haber perdido el juego con #France cual hubiese sido la situación?\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:30\n","-------------------------------------------\n"," En caso de haber perdido el juego con  cual hubiese sido la situación?\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:35\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:35\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:40\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:40\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:45\n","-------------------------------------------\n","\n","-------------------------------------------\n","Time: 2022-12-21 02:12:45\n","-------------------------------------------\n","\n"]}],"source":["# start streaming process, wait for 600s and then stop.\n","ssc.start()\n","time.sleep(STREAM_TIME)\n","ssc.stop(stopSparkContext = False, stopGraceFully = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}